---
title: "Taller RLM 1"
author: "-"
date: "3/12/2021"
output: pdf_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# Librerías aquí.
library("readr")
library("tidyverse")
library("summarytools")
library("car")
library("rsm")
library("rgl")
library("GGally")
library("DT")
library("scales")
library("stargazer")
library("olsrr")
library("xtable")
```

```{r}
datos <- read_csv("archivos/winequality-red.csv")
#datos=read.table(file.choose(),header=T,sep=",",dec=".")
datos1<-datos[1:100,c(1:5,12)]

datos <- datos1 %>% 
  rename(Fija = `fixed acidity`) %>% 
  rename(Volatil = `volatile acidity`) %>% 
  rename(Citrico = `citric acid`) %>% 
  rename(Azucar = `residual sugar`) %>% 
  rename(Cloruros = chlorides) %>% 
  rename(Calidad = quality)

rm(datos1)
```

```{r}
attach(datos)
modelo = lm(Calidad ~ Fija + Volatil + Citrico + Azucar + Cloruros, datos)
summary(modelo)
```

# Punto siete.

```{r}
#anova(modelo)
```
\begin{tabular}{|c|l|c|ccc}
\hline
Fuente   & \multicolumn{1}{c|}{SS1}                                      & Df & \multicolumn{1}{c|}{$F_0$}   & \multicolumn{1}{c|}{Pr($f_{1,94}$>$F_0$)} & \multicolumn{1}{c|}{Test asociado}                                      \\ \hline
Fija     & $\text{SSR}(X_1)$=0.474                                       & 1  & \multicolumn{1}{c|}{1.2632}  & \multicolumn{1}{c|}{0.2639}               & \multicolumn{1}{c|}{$H_{0}$: $\beta_{1}=0$ vs $H_{A}:\beta_{1} \neq 0$} \\ \hline
Volatil  & $\text{SSR}(X_2 | X_1)$=2.919                                 & 1  & \multicolumn{1}{c|}{7.7829}  & \multicolumn{1}{c|}{0.006386}             & \multicolumn{1}{c|}{$H_{0}$: $\beta_{2}=0$ vs $H_{A}:\beta_{2} \neq 0$} \\ \hline
Citrico  & $\text{SSR}(X_3 | X_1,X_2)$=3.840                             & 1  & \multicolumn{1}{c|}{10.2384} & \multicolumn{1}{c|}{0.001876}             & \multicolumn{1}{c|}{$H_{0}$: $\beta_{3}=0$ vs $H_{A}:\beta_{3} \neq 0$} \\ \hline
Azucar   & $\text{SSR}(X_4 | X_1,X_2,X_3)$=0.000                         & 1  & \multicolumn{1}{c|}{0.0003}  & \multicolumn{1}{c|}{0.987118}             & \multicolumn{1}{c|}{$H_{0}$: $\beta_{4}=0$ vs $H_{A}:\beta_{4} \neq 0$} \\ \hline
Cloruros & $\text{SSR}(X_5 | X_1,X_2,X_3,X_4)$=0.262                     & 1  & \multicolumn{1}{c|}{0.6997}  & \multicolumn{1}{c|}{0.404997}             & \multicolumn{1}{c|}{$H_{0}$: $\beta_{5}=0$ vs $H_{A}:\beta_{5} \neq 0$} \\ \hline
Error    & \multicolumn{1}{c|}{$\text{SSE}(X_1,X_2,X_3,X_4,X_5)$=35.255} & 94 & \multicolumn{3}{c}{}                                                                                                                               \\ \cline{1-3}
\end{tabular}
\end{table}

Empezando por las sumas de cuadrados secuenciales (tipo 1), tenemos la anterior tabla, como podemos observar los menores valores para las sumas de cuadrados de tipo I son:

1\. $\text{SSR}(X_4 | X_1, X_2, X_3) = 0.000$

2\. $\text{SSR}(X_5 | X_1, X_2, X_3, X_4) = 0.262$

3\. $\text{SS1}_{X_1} = 0.474$

La variable con menor valor en la suma de cuadrados en este caso es Azúcar, lo que significa que al añadir la variable Azúcar dado que las covariables Acidez fija, Acidez Volátil y Ácido cítrico están en el modelo, esta no ayuda a reducir en mayor medida la suma de cuadrados del error lo que no es lo mas conveniente, ya que lo que buscamos es que los residuales de nuestro nuevo modelo sea cada vez más cercano a cero; lo que puede ser un indicio de que la azúcar residual no es significativa para explicar la calidad del vino dado que las otras covariables mencionadas anteriormente estan en el modelo; de manera similar sucede con las covariables Fija y Cloruros.

Para comprobar las sospechas la misma tabla anova nos proporciona el P valor de las variables, con los cuales podemos concluir que no hay evidencia suficiente para rechazar la hipótesis nula:

* Lo cual en el caso de la variable Fija significa que la Acidez fija no es significativa para explicar la calidad del vino dado que no hay otras covariables en el modelo.

* Lo cual en el caso de la variable Azúcar significa que la azúcar residual no es significativa para explicar la calidad del vino dado que Acidez fija, Acidez Volátil y Ácido cítrico están en el modelo .

* En el caso de la variable Cloruros, los cloruros nos son significativos para explicar la calidad del vino dado que las covariables Acidez fija, Acidez Volátil, Ácido cítrico y azúcar estan en el modelo.


```{r}
#Anova(modelo)
```
\begin{table}[h]
\begin{tabular}{|c|l|c|ccc}
\hline
Fuente   & \multicolumn{1}{c|}{SS2}                                      & Df & \multicolumn{1}{c|}{$F_0$}   & \multicolumn{1}{c|}{Pr($f_{1,94}$>$F_0$)} & \multicolumn{1}{c|}{Test asociado}                                      \\ \hline
Fija     & $\text{SSR}(X_1 | X_2,X_3,X_4,X_5)$=0.793                     & 1  & \multicolumn{1}{c|}{2.1148}  & \multicolumn{1}{c|}{0.149211}             & \multicolumn{1}{c|}{$H_{0}$: $\beta_{1}=0$ vs $H_{A}:\beta_{1} \neq 0$} \\ \hline
Volatil  & $\text{SSR}(X_2 | X_1,X_3,X_4,X_5)$=6.671                     & 1  & \multicolumn{1}{c|}{17.7867} & \multicolumn{1}{c|}{5.685e-05}            & \multicolumn{1}{c|}{$H_{0}$: $\beta_{2}=0$ vs $H_{A}:\beta_{2} \neq 0$} \\ \hline
Citrico  & $\text{SSR}(X_3 | X_1,X_2,X_4,X_5)$=4.092                     & 1  & \multicolumn{1}{c|}{10.9110} & \multicolumn{1}{c|}{0.001353}             & \multicolumn{1}{c|}{$H_{0}$: $\beta_{3}=0$ vs $H_{A}:\beta_{3} \neq 0$} \\ \hline
Azucar   & $\text{SSR}(X_4 | X_1,X_2,X_3,X_5)$=0.001                     & 1  & \multicolumn{1}{c|}{0.0016}  & \multicolumn{1}{c|}{0.968006}             & \multicolumn{1}{c|}{$H_{0}$: $\beta_{4}=0$ vs $H_{A}:\beta_{4} \neq 0$} \\ \hline
Cloruros & $\text{SSR}(X_5 | X_1,X_2,X_3,X_4)$=0.262                     & 1  & \multicolumn{1}{c|}{0.6997}  & \multicolumn{1}{c|}{0.404997}             & \multicolumn{1}{c|}{$H_{0}$: $\beta_{5}=0$ vs $H_{A}:\beta_{5} \neq 0$} \\ \hline
Error    & \multicolumn{1}{c|}{$\text{SSE}(X_1,X_2,X_3,X_4,X_5)$=35.255} & 94 & \multicolumn{3}{c}{}                                                                                                                               \\ \cline{1-3}
\end{tabular}
\end{table}
Como podemos observar en la tabla anterior los menores valores para las
sumas de cuadrados de tipo II son:

1\. $\text{SS2}_{X_4} = 0.001$

2\. $\text{SS2}_{X_5} = 0.262$

3\. $\text{SS2}_{X_1} = 0.793$

Para la suma de cuadrados parciales el significado es el mismo lo que cambia esta vez son las covariables que ya están en el modelo antes de agregar la variable de interes, asi las conclusiones que podemos sacar usando la tabla Anova son (usando un nivel de significancia de $\alpha$= 0.05):

* Para la variable Fija no hay evidencia suficiente para rechazar la hipótesis nula, lo que implica que Acidez Fija no es significativa para explicar la calidad del vino dado que las covariables  Acidez Volátil, Ácido cítrico, azúcar y cloruros estan en el modelo.

* Para la variable Azúcar no hay evidencia suficiente para rechazar la hipótesis nula, lo que implica que la azúcar residual no es significativa para explicar la calidad del vino dado que las covariables  Acidez fija, Acidez Volátil, Ácido cítrico, y cloruros estan en el modelo.

* Para la variable Cloruros no hay evidencia suficiente para rechazar la hipótesis nula, lo que implica que los cloruros no son significativos para explicar la calidad del vino dado que las covariables  Acidez fija, Acidez Volátil, Ácido cítrico, y azúcar estan en el modelo.
```{r}
anova(modelo)
```

Como podemos observar en la tabla anterior los menores valores para las
sumas de cuadrados de tipo I son: 1. $\text{SS1}_{X_4} = 0.000$ 2.
$\text{SS1}_{X_5} = 0.262$ 3. $\text{SS1}_{X_1} = 0.474$ Nuestra tabla
anova tambien nos dice que: $\text{SSR}(X_4 | X_1, X_2, X_3) = 0.000$
$\text{SSR}(X_5 | X_1, X_2, X_3, X_4) = 0.262$
$\text{SSR}(X_1) = 0.474$, lo que quiere decir que las sumas de las
diferencias entre la estimación y el valor medio de la variable de
respuesta es mínima, por lo que el modelo propuesto no es
suficientemente útil, también podemos verlo con el p-value; rechazamos
la hipótesis y concluimos que la variable no es significativa para cada
modelo planteado.

```{r}
Anova(modelo)
```

Como podemos observar en la tabla anterior los menores valores para las
sumas de cuadrados de tipo II son:

1\. $\text{SS2}_{X_4} = 0.001$

2\. $\text{SS2}_{X_5} = 0.262$

3\. $\text{SS2}_{X_1} = 0.793$

Cada valor nos dice el SSR de cada variable en el modelo completo dadas
las demás (ej. $\text{SSR}(X_4 | X_1, X_2, X_3, X_4) = 0.001$), lo que
quiere decir que las sumas de las diferencias entre la estimación y el
valor medio de la variable de respuesta es mínima, por lo que el modelo
propuesto no es suficientemente útil, también podemos verlo con el
p-value; recordemos que rechazamos la siguiente hipótesis nula cuando el
p-value es pequeño, como podemos ver para $X_1, X_4, X_5$ los p-values
son demasiado grandes si fijamos un $\alpha$ de 0.05, por lo que
concluimos que estas variables no son significativa para cada el modelo
ajustado.

$$
Y_i = \beta_0 + \beta_1X_{i1} + \beta_2X_{i2} +\beta_3X_{i3} +\beta_4X_{i4} + \beta_5X_{i5} + E_i\ , \text{con} \ E \sim N(0, \sigma^2) \\\ 
\text{H}_0 : \beta_j = 0 \text{ vs. }\text{H}_1 :  \beta \neq 0
$$

# Punto ocho. Gráficos de los residuales estudentizados vs. Valores ajustados y contra las variables de regresión utilizadas.

```{r, fig.width=8, fig.height=4}
par(mfrow = c(1, 2))

plot(
  datos$Calidad ,
  rstudent(modelo),
  ylim = c(
    min(rstudent(modelo),-2 * summary(modelo)$sigma),
    max(rstudent(modelo), 2 * summary(modelo)$sigma)
  ),
  cex = 1.2,
  xlab = "Valores de Calidad presentes",
  ylab = "Residuales estudentizados"
)
abline(h = c(-2, 0, 2), col = 2)

plot(
  fitted(modelo),
  rstudent(modelo),
  ylim = c(
    min(rstudent(modelo),-2 * summary(modelo)$sigma),
    max(rstudent(modelo), 2 * summary(modelo)$sigma)
  ),
  xlab = "Valores de Calidad ajustada",
  ylab = "Residuales estudentizados",
  cex = 1.2
)
abline(h = c(-2, 0, 2), col = 2)


```

Como podemos ver en las gráficas anteriores los residuales
estudentizados tienen ciertos patrones, en la primera gráfica observamos
que entre más alta sea la calidad estos tienden a pasar de negativos a
positivos (modelo lineal entre $x$ y $y$ no es adecuado) y, además, que
cuando el valor es de calidad es $4$ la varianza está mucho más dispersa
que cuando el valor de la calidad es $7$, haciendo que la varianza no
sea constante.

Un motivo de esto puede ser que no se cuenta con un número considerable
de observaciones, por lo que el modelo puede ser susceptible a
observaciones atípicas o influcienciadoras.

En la gráfica de valores de la calidad ajustada por el modelo vs.
residuales estudentizados podemos ver que tiene un efecto similar, pero
en este los residuales están un poco más centrados.

```{r, fig.width=7, fig.height=6}
residualPlots(
  modelo,
  tests = FALSE,
  type = "rstudent",
  quadratic = FALSE,
  fitted = FALSE,
  col = 2,
  cex = 1.5,
  cex.lab = 1.5, cex.axis = 1.5
)
```

En esta gráfica podemos observar el comportamiento de las variables
utilizadas para la regresión vs. los residuales, al parecer no hay
ningún indicio de que alguna variable afecte el comportamiento de la
varianza de los residuales.

# Punto nueve. Gráfica de probabilidad normal para los residuales estudentizados. ¿Existen razones para dudar de la hipótesis de normalidad sobre los errores en este modelo?

```{r, fig.width=9, fig.height=9}
test = shapiro.test(rstudent(modelo)) #Test de normalidad sobre residuales estudentizados
qqPlot(rstudent(modelo))#, envelope=list(level=0.95))
legend("topleft", legend = rbind(c("Statistic W", "p.value"), round(c(
  test$statistic, test$p.value
), digits = 5)), cex = 1.2)
```

Como podemos ver en el gráfico hay datos que se desvían demasiado de los
cuantiles teóricos de la distribución normal, lo cual es una gran señal para dudar de la normalidad de los residuales.

Realizamos el test de Shapiro-Wilk donde la hipótesis nula es
que nuestros errores provienen de una distribución normal, podemos ver
que el p-value es igual a $0.00003$, muchísimo menor a cualquier valor
de $\alpha$ que podamos fijar, por lo que rechazamos la hipótesis nula y
afirmamos que hay suficiente evidencia para decir que los errores
residuales no siguen una distribución normal.

# Punto diez. Presencia de observaciones atípicas, de balanceo y/o influencíales.

```{r}
influence.measures(modelo)$is.inf 
```


```{r, echo=FALSE, results='asis'}
# MEDIDAS DE INFLUENCIA
tabla <- influence.measures(modelo)$is.inf 
print(xtable(tabla), type="latex", comment=FALSE)

```

Como se observa en la tabla anterior los datos influenciables son:

Según la medida DFBetas, los datos influenciables son: 34

Según la medida DFFITS, los datos influenciables son: 34, 47

Según la medida COVRATIO, los datos influenciables son: 4, 8, 9, 17, 18,
19, 20, 34, 38, 39, 43, 63, 82, 84, 95

Según la Distancia de Cook ningún dato es influenciable.

**DFBETAS**


```{r, fig.width=15, fig.height=8, dpi=500}
ols_plot_dfbetas(modelo)
```

Como podemos ver el dato numero 34 supera el limite fijado en para los
datos de azúcar, recordemos que una observación es candidata a ser
influencial mediante este metodo si $|DFBETAS_{j(i)}| > 2/\sqrt{n}$, en este caso nuestro
limite es igual a $2/\sqrt{100} = 0.2$

**DFFITS**

Como podemos ver en la gráfica hay varios datos que superan el
limite fijado, recordemos que una observación es candidata a ser
influencial si $|DFFITS_{(i)} | > 2\sqrt{\frac{k+1}{n}}$, en este caso
nuestro limite es igual a $2\sqrt{\frac{5+1}{100}} \approx 0.49$, con
esto en mente, los datos mas potencialmente influencíales de
acuerdo a esta medida, en orden, son: 34, 47, 17, 46

```{r, fig.width=7, fig.height=5, dpi= 500}
ols_plot_dffits(modelo)
```

**COVRATIO**

Como podemos ver los datos numero supera el limite fijado en para los
datos de azúcar, recordemos que una observación es candidata a ser
influencial si $|COVRATIO_{i} - 1| > 3(k+1)/n$, en este caso; usamos $R$
y encontramos los datos que cumplen la condición, a continuación los
datos potencialmente influencíales y su $COVRATIO$:

```{r}
covratio(modelo)[abs(covratio(modelo) - 1) > (3*6)/100]

```

**DISTANCIA DE COOK**


```{r}
#para validar
#cooks.distance(modelo) > 1
```

```{r, fig.width=8, fig.height=5}
ols_plot_cooksd_bar(modelo)
```

Validamos y encontramos que efectivamente ningún valor sobrepasa $1$,
pero podemos ver que la observación $34$ está demasiado lejos de las
demás, por lo que la tendremos en cuenta.

**Residuales estudentizados (internamente estudentizados)**


```{r, fig.width=8, fig.height=4}
ols_plot_resid_stud(modelo)
```

En este gráfico podemos ver que ninguna observación sobrepasa el limite
fijado de $|e_i| > 3$, por lo que por este método no encontramos ninguna
observación atípica.



```{r, fig.width=9, dpi=500}
ols_plot_resid_lev(modelo)

```
En esta gráfica se grafican los hat-values vs. residuales
estudentizados, como podemos observar la gráfica usa un limite
diferente, este limite es $0.12$, segun hemos visto en clase los limite
que fijamos son $\pm3$, con el cual obtendiramos que ningún dato es una
observación atípica, pero este se encuentra calculado de una forma
diferente, lo cual puede darnos un indicio a cuales podrían ser
observaciones atípicas.

En la gráfica anterior tambien podemos observar que los puntos de balanceo
pueden ser las observaciones 34, 82, 84, 39, 47, 18, 95, 20, 43, 4
basándonos en su valor $h_{ii}$ y el limite usado $h_{ii} >2(k+1)/n$, que
equivale a $h_{ii} > 0.12$, como se puede observar en la gráfica.

```{r, fig.width=8}
ols_plot_resid_stud_fit(modelo)
```
